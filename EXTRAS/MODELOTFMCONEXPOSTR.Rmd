---
title: "HIPOTESIS GRAVEDAD DEL ACCIDENTE EN BASE AL TIPO Y SEXO"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##CONEXIÓN CON POSTGRES

Instalo los paquetes correspondientes, ejecuto el siguiente comando y compruebo que se haya conectado satisfactoriamente.

```{r}
#install.packages("RPostgreSQL")
require("RPostgreSQL")

# Guardar el Password para poder posteriormente eliminarlo
pw <- { "1796vd"}

# Leer el driver de PostgreSQL
drv <- dbDriver("PostgreSQL")

# Crear la conexion con la base de datos
con <- dbConnect(drv, dbname = "postgres",
                 host = "localhost", port = 5432,
                 user = "postgres", password = pw)
# Eliminar el Password
rm(pw) 

# Chequear que existe la tabla de la base de datos para comprobar la conexión
dbExistsTable(con, "descripcion_carnet")
```



## MODELO 1: Gravedad del herido en función de su papel y género

https://rpubs.com/Joaquin_AR/383283

Importo los paquetes más genéricos

```{r}
library(readr)
library(ISLR)
library(mgcv)
library(ggplot2)
library(caret)
library(dplyr)
library(magrittr)
library(tidyverse)
library(rpart)
library(rpart.plot)
```


#Creo una tabla R con la información que se va a utilizar

Primero se estudia la tabla 

```{r}
datos <- dbGetQuery(con, "SELECT * FROM victima_involucrada")
head(datos)
```

Se selecciona las columnas que se van a utilizar 

```{r}
datos <- dbGetQuery(con, "SELECT id_victima, edad, id_desc_sexo, id_desc_condicion_fisica, id_desc_tipo_victima  FROM victima_involucrada")
head(datos)
```

Ahora se relaciona con las otras tablas para obtener la  descripcione de la condicion fisica

```{r}
datos <- dbGetQuery(con, 
                    "SELECT victima_involucrada.id_victima, victima_involucrada.edad, descripcion_sexo_victima.desc_sexo, descripcion_tipologia_victima.desc_tipologia, descripcion_condicion_fisica_victima.desc_condicion_fisica
FROM victima_involucrada
  INNER JOIN descripcion_condicion_fisica_victima
    ON victima_involucrada.id_desc_condicion_fisica=descripcion_condicion_fisica_victima.id_desc_condicion_fisica
  INNER JOIN descripcion_tipologia_victima
    ON victima_involucrada.id_desc_tipo_victima=descripcion_tipologia_victima.id_desc_tipologia
INNER JOIN descripcion_sexo_victima ON victima_involucrada.id_desc_sexo=descripcion_sexo_victima.id_desc_sexo")
head(datos)
```

Veo la variable Condicion fisica que es con la que voy a trabajar en el modelo

```{r}
unique(datos$desc_condicion_fisica)
```


Agrupo por gravedad

```{r}
datos$desc_condicion_fisica<-ifelse(datos$desc_condicion_fisica == "Herido grave", "Grave", datos$desc_condicion_fisica)

datos$desc_condicion_fisica<-ifelse(datos$desc_condicion_fisica == "Herido grave: Hospitalización superior a 24h", "Grave", datos$desc_condicion_fisica)

datos$desc_condicion_fisica<-ifelse(datos$desc_condicion_fisica == "Herido leve", "Leve", datos$desc_condicion_fisica)

datos$desc_condicion_fisica<-ifelse(datos$desc_condicion_fisica == "Herido leve: Con asistencia sanitaria en lugar de accidente", "Leve", datos$desc_condicion_fisica)

datos$desc_condicion_fisica<-ifelse(datos$desc_condicion_fisica == "Herido leve: Hospitalización hasta 24h", "Leve", datos$desc_condicion_fisica)

datos$desc_condicion_fisica<-ifelse(datos$desc_condicion_fisica == "Herido leve: Rechaza asistencia sanitaria", "Leve", datos$desc_condicion_fisica)

datos$desc_condicion_fisica<-ifelse(datos$desc_condicion_fisica == "Muerte", "Muerto", datos$desc_condicion_fisica)

datos$desc_condicion_fisica<-ifelse(datos$desc_condicion_fisica == "Muerte (dentro 24h posteriores accidente)", "Muerto", datos$desc_condicion_fisica)

```

Reviso que se hayen agrupado

```{r}
unique(datos$desc_condicion_fisica)
```

Convierto a factor que es la mejor manera de trabajar los modelos

```{r}
datos$desc_condicion_fisica<-as.factor(datos$desc_condicion_fisica)
```

Convierto la edad en numerico

```{r}
datos$edad<- as.numeric(datos$edad)
```

Reviso la estructura nuevamente
```{r}
str(datos)
```

## Análisis exploratorio de los datos

Quiero predecir la variable "Condicion física" que es un factor con varios niveles.

Numero de observaciones del set de datos

```{r}
nrow(datos)
```

Detección si hay alguna fila incompleta

```{r}
any(!complete.cases(datos))
```

Todas las filas están completas

Veo los niveles que contiene la columna que quiero predecir

```{r}
levels(datos$desc_condicion_fisica)
```


## Distribución de las variables respuestas

Cuando se crea un modelo, es muy importante estudiar la distribución de la variable respuesta, ya que, a fin de cuentas, es lo que nos interesa predecir.

```{r}
ggplot(data = datos, aes(x = desc_condicion_fisica, y = ..count.., fill = desc_condicion_fisica)) +
  geom_bar() +
  scale_fill_manual(values = c( "red", "green", "black")) +
  labs(title = "Condición") +
  theme_bw() +
  theme(legend.position = "bottom")
```



Tabla de frecuencias

```{r}
table(datos$desc_condicion_fisica)
```


```{r}
prop.table(table(datos$desc_condicion_fisica)) %>% round(digits = 4)
```

Se considera que el modelo predictivo es útil cuando el porcentaje de acierto es mayor al esperado por la probabilidad. En este caso se observa una probabilidad del 98% de
que sea un herido leve, el modelo debe intentar acercarse.

## Distribución de variables 

El objetivo de estudio es predecir la condición de la victima del accidente. Analizando los datos de esta forma, se pueden empezar a extraer ideas sobre qué variables están más relacionadas.

Analizando la variable edad al ser numérica

```{r}
library(ggpubr)
p1 <- ggplot(data = datos, aes(x = edad, fill = desc_condicion_fisica)) +
      geom_density(alpha = 0.5) +
      scale_fill_manual(values = c("red", "green", "black")) +
      geom_rug(aes(color = desc_condicion_fisica), alpha = 0.5) +
      scale_color_manual(values = c("red", "green", "black")) +
      theme_bw()
p2 <- ggplot(data = datos, aes(x = desc_condicion_fisica, y = edad, color = desc_condicion_fisica)) +
      geom_boxplot(outlier.shape = NA) +
      geom_jitter(alpha = 0.3, width = 0.15) +
      scale_color_manual(values = c("red", "green", "black")) +
      theme_bw()
final_plot <- ggarrange(p1, p2, legend = "top")
final_plot <- annotate_figure(final_plot, top = text_grob("Edad", size = 15))
final_plot
```


Analizando el tipo de persona

```{r}
ggplot(data = datos, aes(x = desc_tipologia, y = ..count.., fill = desc_condicion_fisica)) +
  geom_bar() +
  scale_fill_manual(values = c("red", "green", "black")) +
  labs(title = "Tipo persona") +
  theme_bw() +
  theme(legend.position = "bottom")
```

Tabla de frecuencias relativas de gravedad por tipo

```{r}
prop.table(table(datos$desc_tipologia, datos$desc_condicion_fisica), margin = 1) %>% round(digits = 4)
```

Ahora con la variable sexo 

```{r}
ggplot(data = datos, aes(x = desc_sexo, y = ..count.., fill = desc_condicion_fisica)) +
  geom_bar() +
  scale_fill_manual(values = c("red", "green", "black")) +
  labs(title = "Sexo") +
  theme_bw() +
  theme(legend.position = "bottom")
```


##Contraste de proporciones

Para la identificación de potenciales predictores cualitativos, es interesante encontrar las variables y niveles de las mismas que muestran una proporción de estado leve alejada de lo esperado por el nivel basal, en este caso el 98%

Para facilitar este tipo de análisis, resulta útil crear variables dummy con todos los niveles de las variables cualitativas (proceso conocido como binarización o one hot encoding) y aplicar un test de contraste de proporciones.

```{r}
head(datos)
```


```{r}
# Se excluyen las variables continuas y las cualitativas que no agrupan a las
# victimas.
datos_cualitativos <- datos %>%
                      select(-edad, -id_victima)

datos_cualitativos_tidy <- datos_cualitativos %>%
                           gather(key = "variable", value = "grupo", -desc_condicion_fisica)

# Se eliminan los valores NA para que no se interpreten como un grupo
datos_cualitativos_tidy <- datos_cualitativos_tidy %>% filter(!is.na(grupo))
  
# Se añade un identificador formado por el nombre de la variable y el grupo 
datos_cualitativos_tidy <- datos_cualitativos_tidy %>%
                           mutate(variable_grupo = paste(variable, grupo, sep = "_"))

```


```{r}
# Función que calcula el test de proporciones para la columna "Condicion fisica" de un df
test_proporcion <- function(df){
  n_leves <- sum(df$desc_condicion_fisica == "Leve") 
  n_graves     <- sum(df$desc_condicion_fisica == "Grave")
  n_muertos     <- sum(df$desc_condicion_fisica == "Muertos")
  n_total <- n_leves + n_graves + n_muertos
  test <- prop.test(x = n_leves, n = n_total, p = 0.9807)
  prop_leves <- n_leves / n_total
  return(data.frame(p_value = test$p.value, prop_leves))
}

# Se agrupan los datos por "variable_grupo" y se aplica a cada grupo la función
# test_proporcion()
analisis_prop <- datos_cualitativos_tidy %>%
                 group_by(variable_grupo) %>%
                 nest() %>%
                 arrange(variable_grupo) %>%
                 mutate(prop_test = map(.x = data, .f = test_proporcion)) %>%
                 unnest(prop_test) %>%
                 arrange(p_value) %>% 
                 select(variable_grupo,p_value, prop_leves)
analisis_prop
```

```{r}
# Representación gráfica de la distribución de los 6 grupos con menor p-value
top6_grupos <- analisis_prop %>% pull(variable_grupo) %>% head(6)

# Se crea una función que, dados un dataframe y el nombre de un grupo, genere la
# representación gráfica de supervivientes y no supervivientes.
plot_grupo <- function(grupo, df, threshold_line = 0.9807){

  p <- ggplot(data = df, aes(x = 1, y = ..count.., fill = desc_condicion_fisica)) +
            geom_bar() +
            scale_fill_manual(values = c("red", "green", "black")) +
            # Se añade una línea horizontal en el nivel basal
            geom_hline(yintercept = nrow(df) * threshold_line,
                       linetype = "dashed") +
            labs(title = grupo) +
            theme_bw() +
            theme(legend.position = "bottom",
                  axis.text.x = element_blank(),
                  axis.title.x = element_blank(),
                  axis.ticks.x = element_blank())
  return(p)
}

datos_graficos <- datos_cualitativos_tidy %>%
                  filter(variable_grupo %in% top6_grupos) %>%
                  group_by(variable_grupo) %>%
                  nest() %>%
                  arrange(variable_grupo)

plots <- map2(datos_graficos$variable_grupo, .y = datos_graficos$data,
              .f = plot_grupo)

ggarrange(plotlist = plots, common.legend = TRUE)
```

El listado obtenido muestra, ordenados de menor a mayor p-value, cada uno de los posibles grupos simples en los que se puede diferenciar a las victimas

## División de los datos en entrenamiento y test


Los datos no están ordenados aleatoriamente sino secuencialmente según el año en el que ocurrió el accidente. Esto es un problema importante y se debe 
corregir antes de dividir los datos en entrenamiento y test. Para desordenar la lista de observaciones, se puede usar la función sample() que genera indices aleatorios.

```{r}
shuffle_index <- sample(1:nrow(datos))
head(shuffle_index)
```


Ahora se usa estos índices para generar un ordenamiento aleatorio del conjunto de datos.

```{r}
datos <- datos[shuffle_index, ]
head(datos)
```

Antes de entrenar el modelo vamos a dividir el conjunto de datos en entrenamiento y test. La práctica común es 80-20. Crearemos una función con este propósito.


Limpio los datos para que no exista el NA


```{r}
clean_datos <- datos %>%
  select(c(id_victima, desc_tipologia, desc_condicion_fisica, desc_sexo)) %>% 
  na.omit()
glimpse(clean_datos)
head(clean_datos)
clean_datos
```


```{r}
datos_train <- clean_datos %>% dplyr::sample_frac(.8)
datos_test  <- dplyr::anti_join(clean_datos, datos_train, by = 'id_victima') # se debe tener un id
datos_train <- dplyr::select(datos_train, -id_victima)
datos_test <- dplyr::select(datos_test, -id_victima)
```


Se verifica que la distribución de la variable respuesta es similar en el conjunto de entrenamiento y en el de test

```{r}
prop.table(table(datos_train$desc_condicion_fisica))
```


```{r}
prop.table(table(datos_test$desc_condicion_fisica))
```


#Variables con varianza próxima a cero

Dentro del modelo no se deben incluir elementos que tenga varianza cero o cercana porque no generan información.



```{r}
datos %>% select(desc_sexo, desc_tipologia) %>%
          nearZeroVar(saveMetrics = TRUE)
```


En este caso no se incluye la condición física dado que es la que voy a predecir. 

Entre los predictores incluidos en el modelo, no se detecta ninguno con varianza cero o próxima a cero.

#Binarización de variables cualitativas

La binarización consiste en crear nuevas variables dummy con cada uno de los niveles de las variables cualitativas. 


```{r}
library(recipes)
# Se crea un objeto recipe() con la variable respuesta y los predictores. 

objeto_recipe <- recipe(formula = desc_condicion_fisica ~ desc_tipologia + desc_sexo,
                        data =  datos_train)
objeto_recipe
```



```{r}
objeto_recipe <- objeto_recipe %>% step_dummy(all_nominal(), -all_outcomes())
```

Se entrena el objeto recipe

```{r}
trained_recipe <- prep(objeto_recipe, training = datos_train)
trained_recipe
```


```{r}
# Se aplican las transformaciones al conjunto de entrenamiento y de test
datos_train_prep <- bake(trained_recipe, new_data = datos_train)
datos_test_prep  <- bake(trained_recipe, new_data = datos_test)

glimpse(datos_train_prep)
```

```{r}
##RANDOM FOREST Y BOOTSTRAPPING

library(doMC)
library(mlbench)
library(Hmisc)
library(randomForest)
registerDoMC(cores = 4)

# Tamaño de los conjuntos de predictores analizados
subsets <- c(3:11)

# Número de resamples para el proceso de bootstrapping
repeticiones <- 30

# Se crea una semilla para cada repetición de validación.  
set.seed(123)
seeds <- vector(mode = "list", length = repeticiones + 1)
for (i in 1:repeticiones) {
  seeds[[i]] <- sample.int(1000, length(subsets))
} 
seeds[[repeticiones + 1]] <- sample.int(1000, 1)

# Se crea un control de entrenamiento donde se define el tipo de modelo empleado para la selección de variables, en este caso random forest, la estrategia de resampling, en este caso bootstrapping con 30 repeticiones, y las semillas para cada repetición.s.
ctrl_rfe <- rfeControl(functions = rfFuncs, method = "boot", number = repeticiones,
                       returnResamp = "all", allowParallel = TRUE, verbose = FALSE,
                       seeds = seeds)



# Se ejecuta la eliminación recursiva de predictores
set.seed(342)
rf_rfe <- rfe(desc_condicion_fisica ~ ., data = datos_train_prep,
              sizes = subsets,
              metric = "Accuracy",

              # El accuracy es la proporción de clasificaciones correctas
              rfeControl = ctrl_rfe,
              ntree = 500)

```


Se muestra una tabla resumen con los resultados

```{r}
rf_rfe
```

```{r}
rf_rfe$optVariables
```

```{r}
# Valores de accuracy y kappa para cada tamaño de modelo en cada resample.
rf_rfe$resample %>% select(1, 2) %>% head(8)
```


Se puede observar que el accuracy es de aproximadamente 98% en todos los casos. Esto concuerda con los datos ya que el 98% de los heridos son leves; es decir, que si quiero predecir de que sea leve voy a acertar el 98% de las veces. 

En realidad este modelo es más descriptivo que predictivo dado a que como se ha mencionado anteriormente el 98% de los datos se agrupan en heridos leves 

Otro método para realizarlo es 

```{r}
library (MASS)
set.seed(101)

datos.rf= randomForest(desc_condicion_fisica ~ ., data = datos_train_prep)
datos.rf
```



